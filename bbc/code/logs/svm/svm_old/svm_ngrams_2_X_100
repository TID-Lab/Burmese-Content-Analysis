2020-05-23 00:48:21,113 INFO     File loaded: /home/harshil/Harshil/gt/spring2020/research2/ml-evaluation-models/bbc/data/X_100.json
2020-05-23 00:48:21,116 INFO     File loaded: /home/harshil/Harshil/gt/spring2020/research2/ml-evaluation-models/bbc/data/X_100.json
2020-05-23 00:48:21,117 INFO     File loaded: /home/harshil/Harshil/gt/spring2020/research2/ml-evaluation-models/bbc/data/y_100.json
2020-05-23 00:48:21,117 INFO     Data loaded
2020-05-23 00:48:21,117 INFO     Num articles: 250
2020-05-23 00:48:21,117 INFO     Training data size : 200
2020-05-23 00:48:21,117 INFO     Testing data size: 50
2020-05-23 00:48:21,117 INFO     Y encoded
2020-05-23 00:48:21,117 INFO     Data vectorized using Count Vectorizer with 2 ngrams
2020-05-23 00:48:21,207 INFO     Feature names : ['ကက စထရ', 'ကက တယ', 'ကက တလန', 'ကက နက', 'ကက သလစ', 'ကခ နယ', 'ကခ လက', 'ကခ သမ', 'ကင တယ', 'ကင သမ', 'ကစ စတန', 'ကစ လက', 'ကဆ တယ', 'ကဆ ရင', 'ကဆက နယ', 'ကဋ တယ', 'ကဌ တယ', 'ကဌ အပ', 'ကဌ အဖ', 'ကဏ ဍမ'] ...
2020-05-23 00:48:21,207 INFO     Vectorized X train dimensions: (200, 5000)
2020-05-23 00:48:21,207 INFO     Vectorized X test dimensions: (50, 5000)
2020-05-23 00:48:22,912 INFO     classifier: SVM Classifier (Grid search)
2020-05-23 00:48:22,914 INFO     
              precision    recall  f1-score   support

           0       0.87      0.74      0.80        27
           1       0.74      0.87      0.80        23

    accuracy                           0.80        50
   macro avg       0.81      0.81      0.80        50
weighted avg       0.81      0.80      0.80        50

2020-05-23 00:48:22,915 INFO     Grid SVM Best Parameters: {'C': 0.1, 'gamma': 10, 'kernel': 'linear'}
2020-05-23 00:48:22,918 INFO     
params mean_test_score
"{'C': 0.01, 'gamma': 10, 'kernel': 'linear'}" 0.725
"{'C': 0.01, 'gamma': 10, 'kernel': 'rbf'}" 0.51
"{'C': 0.01, 'gamma': 1, 'kernel': 'linear'}" 0.725
"{'C': 0.01, 'gamma': 1, 'kernel': 'rbf'}" 0.51
"{'C': 0.01, 'gamma': 0.1, 'kernel': 'linear'}" 0.725
"{'C': 0.01, 'gamma': 0.1, 'kernel': 'rbf'}" 0.51
"{'C': 0.01, 'gamma': 0.01, 'kernel': 'linear'}" 0.725
"{'C': 0.01, 'gamma': 0.01, 'kernel': 'rbf'}" 0.51
"{'C': 0.1, 'gamma': 10, 'kernel': 'linear'}" 0.76
"{'C': 0.1, 'gamma': 10, 'kernel': 'rbf'}" 0.51
"{'C': 0.1, 'gamma': 1, 'kernel': 'linear'}" 0.76
"{'C': 0.1, 'gamma': 1, 'kernel': 'rbf'}" 0.51
"{'C': 0.1, 'gamma': 0.1, 'kernel': 'linear'}" 0.76
"{'C': 0.1, 'gamma': 0.1, 'kernel': 'rbf'}" 0.51
"{'C': 0.1, 'gamma': 0.01, 'kernel': 'linear'}" 0.76
"{'C': 0.1, 'gamma': 0.01, 'kernel': 'rbf'}" 0.51
"{'C': 1, 'gamma': 10, 'kernel': 'linear'}" 0.76
"{'C': 1, 'gamma': 10, 'kernel': 'rbf'}" 0.51
"{'C': 1, 'gamma': 1, 'kernel': 'linear'}" 0.76
"{'C': 1, 'gamma': 1, 'kernel': 'rbf'}" 0.51
"{'C': 1, 'gamma': 0.1, 'kernel': 'linear'}" 0.76
"{'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}" 0.51
"{'C': 1, 'gamma': 0.01, 'kernel': 'linear'}" 0.76
"{'C': 1, 'gamma': 0.01, 'kernel': 'rbf'}" 0.635
"{'C': 10, 'gamma': 10, 'kernel': 'linear'}" 0.76
"{'C': 10, 'gamma': 10, 'kernel': 'rbf'}" 0.51
"{'C': 10, 'gamma': 1, 'kernel': 'linear'}" 0.76
"{'C': 10, 'gamma': 1, 'kernel': 'rbf'}" 0.51
"{'C': 10, 'gamma': 0.1, 'kernel': 'linear'}" 0.76
"{'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}" 0.51
"{'C': 10, 'gamma': 0.01, 'kernel': 'linear'}" 0.76
"{'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}" 0.7
"{'C': 100, 'gamma': 10, 'kernel': 'linear'}" 0.76
"{'C': 100, 'gamma': 10, 'kernel': 'rbf'}" 0.51
"{'C': 100, 'gamma': 1, 'kernel': 'linear'}" 0.76
"{'C': 100, 'gamma': 1, 'kernel': 'rbf'}" 0.51
"{'C': 100, 'gamma': 0.1, 'kernel': 'linear'}" 0.76
"{'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}" 0.51
"{'C': 100, 'gamma': 0.01, 'kernel': 'linear'}" 0.76
"{'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}" 0.7

